{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit comments\n",
    "### Generate PCA based \"toxicity\" score\n",
    "\n",
    "In this notebook, I create a new comment variable \"pca_score\" using a PCA analysis on vote score and number of replies. \n",
    "\n",
    "pca_score is a standardized (-5 to 5 range) score based on comment features that indicates whether the comment was positively or negatively received by other users. A highly negative comment score could be deemed \"toxic\".\n",
    "\n",
    "pca_score will be used to create the toxic vs non-toxic comment label for supervised training of the toxic comment classifiers.\n",
    "\n",
    "The comments were downloaded from a target Reddit using PRAW and a custom script. Each comment has the following associated features:\n",
    "\n",
    "- comment ID#\n",
    "- subreddit name\n",
    "- post ID#\n",
    "- parent ID#\n",
    "- comment timestamp\n",
    "- comment age since post time (secs)\n",
    "- comment age since now (secs)\n",
    "- user ID#\n",
    "- user name\n",
    "- user account created date\n",
    "- user account comment karma\n",
    "- user account link karma\n",
    "- #replies to the comment\n",
    "- contoversial flag state\n",
    "- comment vote score\n",
    "- comment text (converted to ascii)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup notebook and load reddit comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ---\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_best_PCA_score(df, cols2use):\n",
    "    numdims = len(cols2use)-1\n",
    "    pcascores = PCA(n_components=numdims).fit_transform(df[cols2use])\n",
    "    bestR2 = 0\n",
    "    slopesign = 0\n",
    "    bestPCA = []\n",
    "    X = df['score'].values.reshape(-1, 1)\n",
    "    for i in range(numdims):\n",
    "        y =  pcascores[:,i].reshape(-1, 1)\n",
    "        reg = LinearRegression().fit(X,y)\n",
    "        R2 = reg.score(X,y)\n",
    "        if bestR2 < abs(R2):\n",
    "            bestR2 = abs(R2)\n",
    "            slopesign = np.sign(reg.coef_[0][0])\n",
    "            bestPCA = y\n",
    "    if slopesign < 0:\n",
    "        bestscore = -bestPCA\n",
    "    else:\n",
    "        bestscore = bestPCA\n",
    "    return bestscore\n",
    "\n",
    "\n",
    "def create_comment_score(df, subname, outputpath, verbose=True):\n",
    "    # get sign of vote score\n",
    "    df['score_sign'] = (df.score<0).map({True:'negative',False:'positive'})\n",
    "\n",
    "    # convert seconds time difference between post date and comment date into days\n",
    "    df['u_days'] = ((df.time-df.u_created)/86400)\n",
    "\n",
    "    # specify which feature columns to analyze\n",
    "    cols2compare = ['u_comment_karma', 'u_link_karma', 'num_replies', \n",
    "                    'u_days', 'score']\n",
    "\n",
    "    # plot freq histograms for selected features\n",
    "    if verbose:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        for plotnum, colname in zip(range(len(cols2compare)), cols2compare):\n",
    "            std3 = 3*df[colname].std()\n",
    "            plt.tight_layout()\n",
    "            plt.subplot(2,3,plotnum+1)\n",
    "            plt.hist(df[colname], range=(-std3,std3), log=True)\n",
    "            plt.title(colname)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.90]);\n",
    "        plt.suptitle(subname+'- original feature histograms, log y scale', fontsize=20);\n",
    "        plt.show();\n",
    "    \n",
    "    # log transform features\n",
    "    # create a new df for all the log transformed features\n",
    "    df_log = df.copy()\n",
    "\n",
    "    # comment karma can be negative, so compute logs differently\n",
    "    df_log.u_comment_karma[df_log.u_comment_karma>0] = np.log(\n",
    "        df_log.u_comment_karma[df_log.u_comment_karma>0].astype(float))\n",
    "    df_log.u_comment_karma[df_log.u_comment_karma<0] = -np.log(\n",
    "        df_log.u_comment_karma[df_log.u_comment_karma<0].abs().astype(float))\n",
    "    df_log.num_replies[df_log.num_replies>0] = np.log(\n",
    "        df_log.num_replies[df_log.num_replies>0].astype(float))\n",
    "    # comment score can be negative, so compute logs differently\n",
    "    df_log.score[df_log.score>0] = np.log(df_log.score[df_log.score>0].astype(float))\n",
    "    df_log.score[df_log.score<0] = -np.log(df_log.score[df_log.score<0].abs().astype(float))\n",
    "\n",
    "    # make numreplies negative if vote score is negative\n",
    "    df_log['num_replies_fixed'] = df_log.num_replies\n",
    "    df_log.num_replies_fixed[df_log.score<0] = -df_log.num_replies_fixed[df_log.score<0]\n",
    "    \n",
    "    # plot correlation matrix of fixed features\n",
    "    # Generate a mask for the upper triangle\n",
    "    if verbose:\n",
    "        mask = np.zeros([len(cols2compare),len(cols2compare)], dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        # Generate a custom diverging colormap\n",
    "        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        sns.heatmap(df_log[cols2compare].corr(), mask=mask, cmap=cmap, \n",
    "                    center=0, annot=True, fmt='1.3f',\n",
    "                    square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "        plt.title('Subreddit '+subname+': selected feature correlations, all samples\\n');\n",
    "        plt.show();\n",
    "\n",
    "    # do PCA analysis\n",
    "    cols2use = ['score', 'num_replies_fixed', 'u_comment_karma' ]\n",
    "    bestscore = get_best_PCA_score(df_log, cols2use)\n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.scatter(df_log['score'], bestscore,  color='blue',  s=1)\n",
    "        plt.tight_layout();\n",
    "        plt.xlabel('Log vote score')\n",
    "        plt.ylabel('PCA2 score')\n",
    "        plt.title('Vote score vs PCA2 score');    \n",
    "\n",
    "    # create output dataframe\n",
    "    df_labeled = df.copy() # copy original unmodified dataframe\n",
    "    \n",
    "    # using PCA 2 as score\n",
    "    df_labeled['pca_score'] = bestscore\n",
    "\n",
    "    # range and adjust scores using stds for pos and neg values\n",
    "    stdneg = df_labeled.pca_score.std()\n",
    "    stdpos = stdneg\n",
    "\n",
    "    # standardize the range, treat pos and neg scores separately\n",
    "    df_labeled.pca_score[df_labeled.pca_score<0] = df_labeled.pca_score[df_labeled.pca_score<0]/stdneg\n",
    "    df_labeled.pca_score[df_labeled.pca_score>0] = df_labeled.pca_score[df_labeled.pca_score>0]/stdpos\n",
    "    \n",
    "    # threshold scores so that we have a range of +/-5\n",
    "    df_labeled.pca_score[df_labeled.pca_score<-5] = -5\n",
    "    df_labeled.pca_score[df_labeled.pca_score>5] = 5\n",
    "\n",
    "    if verbose:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        df_labeled.pca_score.hist(bins=40)\n",
    "        plt.title(subname+'- standardized and ranged PCA score distribution')\n",
    "        plt.show();\n",
    "        \n",
    "    df_labeled.to_csv(outputpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scoring aww\n",
      "   ./data_collected\\comment_sample_aww190309_213310.csv\n",
      "   ./data_collected\\comment_sample_aww190310_215841.csv\n",
      "\n",
      "scoring funny\n",
      "   ./data_collected\\comment_sample_funny190329_191231.csv\n",
      "\n",
      "scoring todayilearned\n",
      "   ./data_collected\\comment_sample_todayilearned190316_224053.csv\n",
      "\n",
      "scoring askreddit\n",
      "   ./data_collected\\comment_sample_askreddit190330_083946.csv\n",
      "\n",
      "scoring photography\n",
      "   ./data_collected\\comment_sample_photography190311_124954.csv\n",
      "   ./data_collected\\comment_sample_photography190311_171008.csv\n",
      "   ./data_collected\\comment_sample_photography190405_200018.csv\n",
      "   ./data_collected\\comment_sample_photography190405_220404.csv\n",
      "\n",
      "scoring gaming\n",
      "   ./data_collected\\comment_sample_gaming190401_091528.csv\n",
      "   ./data_collected\\comment_sample_gaming190401_201437.csv\n",
      "\n",
      "scoring videos\n",
      "   ./data_collected\\comment_sample_videos190402_074146.csv\n",
      "\n",
      "scoring science\n",
      "   ./data_collected\\comment_sample_science190330_225904.csv\n",
      "\n",
      "scoring politics\n",
      "   ./data_collected\\comment_sample_politics190220_002433.csv\n",
      "   ./data_collected\\comment_sample_politics190406_072416.csv\n",
      "   ./data_collected\\comment_sample_politics190518_134954.csv\n",
      "   ./data_collected\\comment_sample_politics190518_135945.csv\n",
      "   ./data_collected\\comment_sample_politics190518_142027.csv\n",
      "   ./data_collected\\comment_sample_politics190518_142758.csv\n",
      "   ./data_collected\\comment_sample_politics190518_144347.csv\n",
      "   ./data_collected\\comment_sample_politics190518_145045.csv\n",
      "   ./data_collected\\comment_sample_politics190518_150616.csv\n",
      "   ./data_collected\\comment_sample_politics190518_151232.csv\n",
      "   ./data_collected\\comment_sample_politics190518_151649.csv\n",
      "   ./data_collected\\comment_sample_politics190518_152248.csv\n",
      "   ./data_collected\\comment_sample_politics190518_152755.csv\n",
      "\n",
      "scoring politicaldiscussion\n",
      "   ./data_collected\\comment_sample_politicaldiscussion190314_155333.csv\n",
      "\n",
      "scoring conservative\n",
      "   ./data_collected\\comment_sample_conservative190312_120735.csv\n",
      "\n",
      "scoring the_Donald\n",
      "   ./data_collected\\comment_sample_the_Donald190312_191452.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# the subreddits I'll be analyzing\n",
    "subnames = ['aww', 'funny', 'todayilearned','askreddit',\n",
    "           'photography', 'gaming', 'videos', 'science',\n",
    "           'politics', 'politicaldiscussion',             \n",
    "           'conservative', 'the_Donald']\n",
    "\n",
    "srcdir = './data_collected/'\n",
    "destdir = './data_scored/'\n",
    "\n",
    "for subname in subnames:\n",
    "    print('\\nscoring',subname)\n",
    "    dfs = []\n",
    "    for filename in glob.glob(srcdir+'comment_sample_'+subname+'*'):\n",
    "        print('  ',filename)\n",
    "        dfs.append(pd.read_csv(filename))\n",
    "    df = pd.concat(dfs).drop_duplicates()\n",
    "    df.dropna(inplace=True)\n",
    "    # remove any deleted or removed comments \n",
    "    df = df[(df.text!='[deleted]') & (df.text!='[removed]')]\n",
    "    outputpath = destdir+'comment_sample_'+subname+'_scored.csv'\n",
    "    create_comment_score(df, subname, outputpath, verbose=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
