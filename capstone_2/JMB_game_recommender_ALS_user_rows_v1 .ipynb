{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Board game recommendation engine using SIngle Value Decomposition\n",
    "### with unrated game cells filled using imputer\n",
    "\n",
    "#### John Burt\n",
    "\n",
    "#### Note: code for this notebook was copied from\n",
    "- JMB_recommendation_engine_SVD_imputer_vs_ALS_user_rows_v3\n",
    "- JMB_recommendation_engine_method_3.1_v3_MB-ALS\n",
    "\n",
    "\n",
    "### Purpose of this notebook:\n",
    "\n",
    "Implement a board game recommender using a game rating dataset from the boardgamegeek.com website. \n",
    "\n",
    "#### The method:\n",
    "\n",
    "- Load data into a pandas dataframe from provided csv files.\n",
    "\n",
    "- Use pivot to convert the data into a games(rows) X users(cols) rating matrix, with NaNs where users haven't rated games (majority of cells).\n",
    "\n",
    "- Drop users who rated too few games, or gave outlier ratings.\n",
    "\n",
    "- Replace all unrated games (NaNs) with estimated ratings values using Alternating Least Squares (ALS). \n",
    "\n",
    "- Run the filled matrix through Single Value Decomposition (SVD) to generate N feature dimensions that describe each game. The result is a set of N dimensional coordinates for each game.\n",
    "\n",
    "- The recommender takes a user specified game title and uses the SVD coordinates to present the games that are nearest neighbors as recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## load data from csv file\n",
    "\n",
    "- Set up plot environment.\n",
    "- boardgame rating data from csv into pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ---\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "# load the boardgame user data\n",
    "#userdata = pd.read_csv('boardgame-users.csv') # NOTE: ALS can take a LONG time to process this many users!\n",
    "#userdata = pd.read_csv('boardgame-elite-users.csv')\n",
    "userdata = pd.read_csv('boardgame-frequent-users.csv')\n",
    "\n",
    "# rename the userID column\n",
    "userdata=userdata.rename(columns = {\"Compiled from boardgamegeek.com by Matt Borthwick\":'userID'})\n",
    "\n",
    "# load the boardgame title data\n",
    "titledata = pd.read_csv('boardgame-titles.csv')\n",
    "\n",
    "# rename the gameID column\n",
    "titledata=titledata.rename(columns = {\"boardgamegeek.com game ID\":'gameID'})\n",
    "\n",
    "# for titledata set game ID as the index\n",
    "titledata = titledata.set_index(\"gameID\")\n",
    "\n",
    "#print(userdata.head())\n",
    "#print(\"\\n\", titledata.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot user rating data, creating users (row) x gameID (col) x rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the user data to create rows of games, with columns of users. \n",
    "# If a user rated a game, it will be at game x user and if not, then the cell will be NAN\n",
    "#rp = userdata.pivot(index=\"userID\", columns=\"gameID\", values=\"rating\")\n",
    "rp = userdata.pivot(index=\"gameID\", columns=\"userID\", values=\"rating\")\n",
    "#rp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some filtering.\n",
    "\n",
    "The purpose of this filtering is to 1) reduce the dataset size but keep the most ratings, and 2) remove potentially malicious and outlier users (people who rate everything a narrow range of values, or rate everything low).\n",
    "\n",
    "Drop users:\n",
    "- Who have rated < threshold # games\n",
    "- Whose scores have range < threshold\n",
    "- Whose score max < threshold\n",
    "\n",
    "Note: this filtering is mostly only useful for the all users data, which has a lot of users who rate few games or only rate high or low, with no range of preference. It has very little effect on the other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 0 < 10 ratings\n",
      "dropped 2 < 1 rating range\n",
      "dropped 0 max rating < 7\n",
      "\n",
      "total #users now = 2471\n"
     ]
    }
   ],
   "source": [
    "mincount = 10 # min num ratings threshold\n",
    "minrange = 1 # min rating range threshold\n",
    "minmax = 7 # max rating min threshold\n",
    "\n",
    "# number of ratings by each user\n",
    "usercounts = np.count_nonzero(~np.isnan(rp.values),0)\n",
    "\n",
    "# drop users with fewer than mincount ratings\n",
    "rp_filt = rp.drop(rp.columns[usercounts<mincount], axis=1)\n",
    "\n",
    "print(\"dropped %d < %d ratings\"%(rp.shape[1]-rp_filt.shape[1], mincount))\n",
    "\n",
    "# rating range for each user\n",
    "userrange = rp_filt.max(axis=0) - rp_filt.min(axis=0)\n",
    "\n",
    "oldnumusers = rp_filt.shape[1]\n",
    "\n",
    "# drop users with rating range less than minrange\n",
    "rp_filt = rp_filt.drop(rp_filt.columns[userrange<minrange], axis=1)\n",
    "\n",
    "print(\"dropped %d < %d rating range\"%(oldnumusers-rp_filt.shape[1], minrange))\n",
    "\n",
    "# max rating range for each user\n",
    "usermax = rp_filt.max(axis=0)\n",
    "\n",
    "oldnumusers = rp_filt.shape[1]\n",
    "\n",
    "# drop users with rating max less than minmax\n",
    "rp_filt = rp_filt.drop(rp_filt.columns[usermax<minmax], axis=1)\n",
    "\n",
    "print(\"dropped %d max rating < %d\"%(oldnumusers-rp_filt.shape[1],minmax))\n",
    "\n",
    "print(\"\\ntotal #users now = %d\"%(rp_filt.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range user scores between 1 - 10.\n",
    "\n",
    "This ensures that all users have the same ratings range. This seems to help the SVD produce more meaningful feature dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userratingmax = rp_filt.max(axis=0)\n",
    "userratingmin = rp_filt.min(axis=0)\n",
    "rp_fixed = 9 * (rp_filt - userratingmin) / (userratingmax-userratingmin) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares method\n",
    "\n",
    "Implement a weighted Alternating Least Squares algorithm. The method attempts to solve for a specified number of missing factors that influence users to rate the games as they do, then uses the factors to guess how users would rate all of the other games they haven't rated. For more on this method, see the link below.\n",
    "\n",
    "I got the idea to use this from:\n",
    "https://bugra.github.io/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt Borthwick's implementation of Alternating Least Squares\n",
    "\n",
    "from numpy import eye\n",
    "from numpy.linalg import solve\n",
    "from numpy.random import rand\n",
    " \n",
    "# def do_ALS(Q, n_iterations=10, lambda_=0.1, n_factors=100, weighted=True, verbose=True ):\n",
    "def do_ALS_MB(ratings, n_factors=4, n_iterations=10, regularization=0.01, \n",
    "              weighted=True, verbose=True ):\n",
    "    #    unrated items should be recorded as zero\n",
    "    #\n",
    "    #    ratings should have an element-wise multiply method, an element-wise minimum method, \n",
    "    #    and a shape attribute, like scipy.sparse matrices do\n",
    "    if verbose: print(\"setting up matrices . . .\")\n",
    "    n_users, n_items = ratings.shape\n",
    "    X = rand(n_users, n_factors)\n",
    "    Y_T = rand(n_items, n_factors)\n",
    "    r = ratings.minimum(1)\n",
    "    if regularization:\n",
    "        regularization *= eye(n_factors)\n",
    "    for iteration in range(1, n_iterations+1):\n",
    "        if verbose: print(\"\\titeration %d of %d . . .\"%(iteration,n_iterations))\n",
    "        for u in range(n_users):\n",
    "            A = r[u].multiply(Y_T.T) @ Y_T\n",
    "            b = ratings[u] @ Y_T\n",
    "            X[u] = solve(A + regularization, b[0])\n",
    "        for i in range(n_items):\n",
    "            A = (r[:, i].multiply(X)).T @ X\n",
    "            b = ratings[:, i].T @ X\n",
    "            Y_T[i] = solve(A + regularization, b[0])\n",
    "    Q_hat = np.dot(X,Y_T.T)\n",
    "    \n",
    "    return Q_hat, X, Y_T.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the missing ratings using the ALS algorithm.\n",
    "\n",
    "The parameters given seem to work OK for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up matrices . . .\n",
      "\titeration 1 of 8 . . .\n",
      "\titeration 2 of 8 . . .\n",
      "\titeration 3 of 8 . . .\n",
      "\titeration 4 of 8 . . .\n",
      "\titeration 5 of 8 . . .\n",
      "\titeration 6 of 8 . . .\n",
      "\titeration 7 of 8 . . .\n",
      "\titeration 8 of 8 . . .\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# run ALS on pivot data to fill in NaN cells with a useful ratings estimate\n",
    "lambda_ = 0.1 # note: changing this doesn't seem to affect much\n",
    "n_factors = 10 # smaller #factors seems to give better results\n",
    "n_iterations = 8 # 8-10 iterations works best for all-user data, 15-20 for elite & frequent users data\n",
    "\n",
    "# replace NaNs (unrated games) with zeros\n",
    "# rp_fixed2 = rp_fixed_users.fillna(0) # user based\n",
    "# rp_fixed2 = rp_fixed.fillna(0) # game based\n",
    "rp_fixed2 = sparse.csr_matrix(rp_fixed.fillna(0))\n",
    "\n",
    "Q_hat, X, Y = do_ALS_MB(rp_fixed2, n_iterations=n_iterations, \n",
    "                        regularization=lambda_, n_factors=n_factors, weighted=True )\n",
    "# Q_hat is our filled in matrix, errors lets us plot how things went\n",
    "# Q_hat, X, Y, errors = do_ALS(rp_fixed2.values, n_iterations=n_iterations, lambda_=lambda_, n_factors=n_factors, weighted=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Truncated SVD. \n",
    "\n",
    "This proces will result in a set of feature values for each game, allowing them to be plotted onto a map that theoretically indicates which games are related to each other by receiving similar ratings by similar users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, SparsePCA, KernelPCA, TruncatedSVD, NMF\n",
    "\n",
    "# number of dimensions for analysis\n",
    "numdims = 4\n",
    "\n",
    "coords = TruncatedSVD(n_components=numdims).fit_transform(Q_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to search for nearest neighbor games in SVD feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def find_nearest_neighbors(coords, x, numnearest):\n",
    "    \n",
    "    # get euclidean distances of all points to x    \n",
    "    dists = cdist(np.reshape(x,(1,-1)),coords) \n",
    "    \n",
    "    ind, = np.argsort(dists)\n",
    "\n",
    "    # return the numnearest nearest neighbors\n",
    "    return ind[:numnearest]\n",
    "    \n",
    "def recommend_games(targettitle, gametitles, coords, num2rec):\n",
    "    \n",
    "    # get coords of target title\n",
    "    targetcoord = coords[gametitles==targettitle,:]\n",
    "    \n",
    "    # find nearest neighbors\n",
    "    ind = find_nearest_neighbors(coords, targetcoord, num2rec+1)\n",
    "    \n",
    "    # Note: first entry will be the target title (distance 0)\n",
    "    return ind[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the recommender algorithm with a list of board games \n",
    "\n",
    "Note: this recommender only uses one example game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like Monopoly, you should try: Battleship, The Game of Life, UNO, Checkers, Exploding Kittens\n",
      "\n",
      "If you like Apples to Apples, you should try: Stratego, Scattergories, Monopoly Deal Card Game, Rummikub, Once Upon a Time: The Storytelling Card Game\n",
      "\n",
      "If you like Zombicide, you should try: Dungeons & Dragons: Castle Ravenloft Board Game, Sentinels of the Multiverse, XCOM: The Board Game, Firefly: The Game, Pathfinder Adventure Card Game: Rise of the Runelords – Base Set\n",
      "\n",
      "If you like Mice and Mystics, you should try: Merchants & Marauders, Zombicide: Black Plague, Pathfinder Adventure Card Game: Rise of the Runelords – Base Set, Blood Bowl: Team Manager – The Card Game, XCOM: The Board Game\n",
      "\n",
      "If you like Love Letter, you should try: Telestrations, Thebes, PitchCar, The Downfall of Pompeii, Kingdomino\n",
      "\n",
      "If you like Ticket to Ride, you should try: Ticket to Ride: Europe, Jaipur, Carcassonne: Expansion 1 – Inns & Cathedrals, Carcassonne, Sushi Go Party!\n",
      "\n",
      "If you like Catan, you should try: No Thanks!, Bohnanza, Carcassonne: Hunters and Gatherers, Coloretto, Mr. Jack Pocket\n",
      "\n",
      "If you like Carcassonne, you should try: Carcassonne: Expansion 1 – Inns & Cathedrals, Vegas Showdown, Carcassonne: Expansion 2 – Traders & Builders, San Juan, For Sale\n",
      "\n",
      "If you like Agricola, you should try: Puerto Rico, Terra Mystica, Brass: Lancashire, Le Havre, Power Grid\n",
      "\n",
      "If you like Terraforming Mars, you should try: Pandemic Legacy: Season 1, A Feast for Odin, Great Western Trail, 7 Wonders Duel, Caverna: The Cave Farmers\n",
      "\n",
      "If you like Caverna: The Cave Farmers, you should try: A Feast for Odin, Great Western Trail, Orléans, Tzolk'in: The Mayan Calendar, Russian Railroads\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targettitles = [\n",
    "    \"Monopoly\", # low rated mass market\n",
    "    \"Apples to Apples\", # higher rated mass market and party\n",
    "    \"Zombicide\", # Thematic co-op, adult theme, miniatures\n",
    "    \"Mice and Mystics\", # Thematic co-op, family theme, miniatures\n",
    "    \"Love Letter\", # social deduction, party, \"filler\"\n",
    "    \"Ticket to Ride\", # very light-weight gateway eurogame \n",
    "    \"Catan\", # light-weight gateway eurogame\n",
    "    \"Carcassonne\", # light-weight gateway eurogame\n",
    "    \"Agricola\", # mid-weight eurogame \n",
    "    \"Terraforming Mars\", # mid-heavy-weight eurogame\n",
    "    \"Caverna: The Cave Farmers\" # heavy eurogame\n",
    "    ]\n",
    "\n",
    "# number of recommended games to present\n",
    "num2recommend = 5\n",
    "\n",
    "# get game titles from titledata\n",
    "gametitles = titledata.title[rp.index].values\n",
    "\n",
    "# give recommendations for each target game \n",
    "for title in targettitles:\n",
    "    recs = recommend_games(title, gametitles, coords, num2recommend)\n",
    "    print('If you like %s, you should try: %s\\n' % \n",
    "          (title, ', '.join(gametitles[recs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
