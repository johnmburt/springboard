{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create complete game info file for recommender app, including SVD features\n",
    "\n",
    "### Springboard Capstone 2 project: building a recommendation engine\n",
    "### John Burt\n",
    "\n",
    "\n",
    "### Purpose of this notebook:\n",
    "\n",
    "Generate a game data file for my Item Search by Nearest Neighbors (ISNN) recommender model. This model uses a \"game coordinate space\" to search for games similar to ones offered by the user as \"liked games\". To generate the coordinate space, I take the ALS filled game x user ratings matrix generated in another notebook and apply PCA along the user dimension to create a reduced set of features for each game to use as coordinates.\n",
    "\n",
    "Output is a data file with game metadata and SVD feature space coordinates. This file will be deployed with the recommender app.\n",
    "\n",
    "\n",
    "#### The method:\n",
    "\n",
    "- Read the game metadata file and ALS filled ratings matrix.\n",
    "- Compute SVD (using sklearn PCA) along user axis to create game coordinates.\n",
    "- Combine game metadata and game coordinates into one dataframe and save it in HDF5 format.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ---\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "datadir = './data/'\n",
    "\n",
    "n_SVD_dims = 85\n",
    "\n",
    "# load game info file\n",
    "games = pd.read_csv(datadir+'bgg_game_info.csv')\n",
    "\n",
    "# load the ALS filled item x user rating matrix\n",
    "# ratings = pd.read_csv(datadir+'mx_items_filled_minr=10.csv')\n",
    "\n",
    "# inputfile = 'bgg_game_mx_filled.h5' # bad\n",
    "inputfile = 'bgg_game_mx_filled_v2.h5' # good\n",
    "\n",
    "# outputfile = \"bgg_game_data_big.h5\" # bad\n",
    "outputfile = \"bgg_game_data_big_v2.h5\" # good\n",
    "\n",
    "# ratings = pd.read_hdf(datadir+'bgg_game_mx_filled.h5', 'mx')\n",
    "ratings = pd.read_hdf(datadir+inputfile, 'mx')\n",
    "\n",
    "# reset gameID as the index\n",
    "ratings.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce user axis using SVD\n",
    "\n",
    "The output is a matrix of features that can be used as \"game coordinates\" in nearest neighor search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "\n",
    "# first, select only games that are present in both the game info and ratings datasets\n",
    "gameids = list(set(games['id']).intersection(set(ratings['gameID'])))\n",
    "\n",
    "# set indices to game id, \n",
    "#  select the intersecting game ids so that rows are in same order\n",
    "sel_games = games.set_index('id').loc[gameids]\n",
    "sel_ratings = ratings.set_index('gameID').loc[gameids]\n",
    "\n",
    "# next, do SVD in n_SVD_dims dims, for rec model features\n",
    "# features = TruncatedSVD(n_components=n_SVD_dims).fit_transform(sel_ratings.values)\n",
    "# Note: I use PCA now, which performs SVD but also normalizes each feature\n",
    "features = PCA(n_components=n_SVD_dims, whiten=True).fit_transform(sel_ratings.values)\n",
    "feature_cols = ['f_%d'%(i) for i in range(n_SVD_dims)]\n",
    "\n",
    "out_games = pd.concat([sel_games, \n",
    "           pd.DataFrame(features, index=sel_games.index, columns=feature_cols)],\n",
    "          axis=1).sort_index().reset_index()\n",
    " \n",
    "# out_games.to_csv(\n",
    "#     datadir+\"bgg_game_data.csv\", index=False, encoding=\"utf-8\")\n",
    "out_games.to_hdf(\n",
    "    datadir+outputfile, key='gamedata', index=False, encoding=\"utf-8\")\n",
    "\n",
    "out_games.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
