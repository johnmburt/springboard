{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project utility functions\n",
    "\n",
    "### Springboard Capstone 2 project: building a recommendation engine\n",
    "### John Burt\n",
    "\n",
    "\n",
    "### Purpose of this notebook:\n",
    "\n",
    "Collect several functions that get used by more than one notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares method\n",
    "\n",
    "About this code: I originally used an ALS algorithm written by my friend and colleague Matt Borthwick, but then I discovered the [OSS project implicit](https://implicit.readthedocs.io/en/latest/als.html), which implemented a much faster ALS algorithm. I've kept Matt's code here because it might come in handy some time, but for the project I always use implicit now. The entry function, do_ALS_df allows you to specify which version of the algorithm to use.\n",
    "\n",
    "For more about the optimizations used by implicit's ALS method, see [Applications of the Conjugate Gradient Method for ImplicitFeedback Collaborative Filtering](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.379.6473&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt Borthwick's implementation of Alternating Least Squares\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import eye\n",
    "from numpy.linalg import solve\n",
    "from numpy.random import rand\n",
    "from scipy import sparse\n",
    "\n",
    "#*****************************************************\n",
    "# ALS calculation using Matt Borthwick's implementation\n",
    "def do_ALS_MB(iu_mx_sparse, \n",
    "              n_factors=4, \n",
    "              n_iterations=10, \n",
    "              regularization=0.01, \n",
    "              weighted=True, \n",
    "              verbose=True ):\n",
    "    #    unrated items should be recorded as zero\n",
    "    #\n",
    "    #    iu_mx_sparse should have an element-wise multiply method, an element-wise minimum method, \n",
    "    #    and a shape attribute, like scipy.sparse matrices do\n",
    "    if verbose: \n",
    "        print(\"setting up matrices, %d iterations: \"%(n_iterations),end='')\n",
    "    n_users, n_items = iu_mx_sparse.shape\n",
    "    X = rand(n_users, n_factors)\n",
    "    Y_T = rand(n_items, n_factors)\n",
    "    r = iu_mx_sparse.minimum(1)\n",
    "    if regularization:\n",
    "        regularization *= eye(n_factors)\n",
    "    for iteration in range(1, n_iterations+1):\n",
    "        if verbose: print(\"%d,\"%(iteration),end='')\n",
    "        for u in range(n_users):\n",
    "            A = r[u].multiply(Y_T.T) @ Y_T\n",
    "            b = iu_mx_sparse[u] @ Y_T\n",
    "            X[u] = solve(A + regularization, b[0])\n",
    "        for i in range(n_items):\n",
    "            A = (r[:, i].multiply(X)).T @ X\n",
    "            b = iu_mx_sparse[:, i].T @ X\n",
    "            Y_T[i] = solve(A + regularization, b[0])\n",
    "#     Q_hat = np.dot(X,Y_T.T)\n",
    "    \n",
    "    return X, Y_T\n",
    "\n",
    "\n",
    "#*****************************************************\n",
    "# ALS calculation using the implicit ALS package\n",
    "import os  \n",
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "\n",
    "def do_ALS_implicit(iu_mx_sparse, \n",
    "                        n_factors=4, \n",
    "                        n_iterations=10, \n",
    "                        regularization=0.01, \n",
    "                        weighted=True, \n",
    "                        verbose=True ,\n",
    "                        bm25_K1=10,\n",
    "                        bm25_B=0.8,\n",
    "                        use_native=True, \n",
    "                        use_cg=True, \n",
    "                        use_gpu=False, \n",
    "                   ):\n",
    "    \n",
    "    os.environ['MKL_NUM_THREADS'] = '1'\n",
    "    \n",
    "    als = AlternatingLeastSquares(factors=n_factors, \n",
    "            regularization=regularization, use_native=use_native, \n",
    "            use_cg=use_cg, use_gpu=use_gpu, iterations=n_iterations,\n",
    "            calculate_training_loss=True, num_threads=0)\n",
    "    \n",
    "    if verbose: \n",
    "        print('fitting ALS model')\n",
    "        \n",
    "    if weighted:\n",
    "        als.fit(bm25_weight(sparse.csr_matrix(np.nan_to_num(iu_mx_sparse)), \n",
    "                            K1=bm25_K1, B=bm25_B), show_progress=verbose)\n",
    "    else:\n",
    "        als.fit(sparse.csr_matrix(np.nan_to_num(iu_mx_sparse)), show_progress=verbose)\n",
    "    \n",
    "    return als.item_factors, als.user_factors\n",
    "\n",
    "#*****************************************************\n",
    "def scale_to_mx(mx1, mx2):\n",
    "    \"\"\"Scale mx2 to mx1's mean and std\"\"\"\n",
    "    return ((mx2-np.nanmean(mx2)) * (np.nanstd(mx1)/np.nanstd(mx2)) + \n",
    "            np.nanmean(mx1))\n",
    "    \n",
    "#*****************************************************\n",
    "def do_ALS_df(df, ALS_method='implicit', scale=True, return_utilmx=True, **args):\n",
    "    \"\"\"run ALS on array to fill in NaN cells \n",
    "    with a useful iu_mx_sparse estimate:\n",
    "    user_factors = user hidden factors\n",
    "    item_factors = item hidden factors\n",
    "    \"\"\"\n",
    "\n",
    "    if ALS_method != 'implicit':\n",
    "        item_factors, user_factors = do_ALS_MB(\n",
    "            sparse.csr_matrix(np.nan_to_num(df.values)), **args)\n",
    "    else:\n",
    "        item_factors, user_factors = do_ALS_implicit(\n",
    "            sparse.csr_matrix(np.nan_to_num(df.values)), **args)\n",
    "        \n",
    "    if not return_utilmx:\n",
    "        return item_factors, user_factors\n",
    "\n",
    "    else:\n",
    "        if scale:\n",
    "            return (pd.DataFrame( scale_to_mx(df.values, np.dot(item_factors, user_factors.T)),\n",
    "                index=df.index, columns=df.columns), item_factors, user_factors)\n",
    "        else:\n",
    "            return (pd.DataFrame( np.dot(item_factors, user_factors.T),\n",
    "                index=df.index, columns=df.columns), item_factors, user_factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
